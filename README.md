# fk_subjectivity
Codes and data of fake news subjectivity study in portuguese.


fake_news dataset: contain the dataset of fake news in portuguese and the same dataset with the wmd distances calculated.

satire_dataset: contain the dataset of satires in portiguese and the same dataset with the wmd distances calculated.


scenario_fake_real_all: Legitimate vs fact-checked Fake News script and results

scenario_fake_real: Cross-Domain script and results

scenario_fake_real_source: Cross-Source script and results

scenario_satire_real: Satires as Fake News Surrogates script and results

scenario_satire_fake_real: Satires for Fake News Augmentation script and results


The files that are called in each lexiconAnalysis.py script are available at this link (https://www.dropbox.com/s/228zzzliqy8rljs/data.zip?dl=0) (the legitimate news are also in the link - they are too big to put in github). Here, the files are already subdivided considering each experiment scenario. In other words, running the lexiconAnalysis.py scripts (since they can reach the proper files in /data), you should find same results.
